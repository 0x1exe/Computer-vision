{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMvv2P11PtWP"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_anchors(anchors): #basically we get all widths and heights ,compute ratios and areas,apply lexsort on acnhors[sort,:]\n",
        "  w=anchors[:,2]-anchors[:,0]\n",
        "  h=anchors[:,3]-anchors[:,1]\n",
        "  ratios=np.round(h/w,1)\n",
        "  areas=w*h\n",
        "  return anchors[np.lexsort((areas,ratios)),:]\n",
        "\n",
        "def generate_anchors_reference(base_size,scales,ratios):\n",
        "  scales_grid,ratios_grid=np.meshgrid(scales,ratios) #1. meshgrid of scales,ratios reshaped to a vector\n",
        "  base_scales=scales_grid.reshape(-1) #2. compute square of ratios\n",
        "  base_ratios=ratios_grid.reshape(-1)\n",
        "  ratio_sqrt=np.sqrt(base_ratios)    \n",
        "  height=base_scales*ratio_sqrt*base_size  #3. compute width and height with square of ratios\n",
        "  width=base_scales / ratio_sqrt * base_size \n",
        "  center_xy=0  \n",
        "  anchors=np.column_stack([center_xy-width/2, #4.compute four coordinates and stack together\n",
        "                    center_xy-height/2,\n",
        "                    center_xy+width/2,\n",
        "                    center_xy+height/2])\n",
        "  return sort_anchors(anchors)  #5. return with sorting"
      ],
      "metadata": {
        "id": "1zulHUWsPxKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchors_ref = generate_anchors_reference(\n",
        "    256,  # Base size.\n",
        "    [0.5, 1, 2],  # Aspect ratios.\n",
        "    [0.125, 0.25, 0.5, 1, 2],  # Scales.\n",
        "    )"
      ],
      "metadata": {
        "id": "8oeIZEc7UHJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANCHOR_BASE_SIZE = 16\n",
        "ANCHOR_RATIOS = [0.5, 1, 2]\n",
        "ANCHOR_SCALES = [0.125, 0.25, 0.5, 1, 2]\n",
        "feature_map_shape=(3,16,16,256)\n",
        "def generate_anchors(feature_map_shape): \n",
        "  anchor_reference = generate_anchors_reference(ANCHOR_BASE_SIZE, ANCHOR_RATIOS, ANCHOR_SCALES) #1. Obtain references to anchors\n",
        "  num_anchors_per_points=anchor_reference.shape[0] \n",
        "  width=feature_map_shape[2]  #2. Obtain width/height of feature map\n",
        "  height=feature_map_shape[1]\n",
        "\n",
        "  shift_x=torch.arange(0,width) * ANCHOR_BASE_SIZE #3. Create vector of shifts in x and y direction\n",
        "  shift_y=torch.arange(0,height) * ANCHOR_BASE_SIZE\n",
        "\n",
        "  shift_x,shift_y=torch.meshgrid(shift_x,shift_y) #4. Meshgrid of shifts + reshape to vector\n",
        "  shift_x,shift_y=shift_x.reshape(-1),shift_y.reshape(-1)\n",
        "\n",
        "  shifts_xy=torch.stack([shift_x,shift_y,shift_x,shift_y]) #5. stack shifts\n",
        "  num_shifts = shifts_xy.shape[1]\n",
        "\n",
        "  all_anchors = torch.tensor(anchor_reference.reshape((1, num_anchors_per_points, 4))) + shifts_xy.reshape((num_shifts, 1, 4))\n",
        "  all_anchors=all_anchors.reshape(height,width,15,4) #6.reshape acnhor_reference and shift it by shifts \n",
        "\n",
        "  return all_anchors"
      ],
      "metadata": {
        "id": "w0L5o8DpssN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_width_upright(bboxes): #bboxes: (num_bboxes,4)\n",
        "  x1, y1, x2, y2 = bboxes[:,0],bboxes[:,1],bboxes[:,2],bboxes[:,3]\n",
        "  width = x2 - x1 + 1\n",
        "  height = y2 - y1 + 1.\n",
        "\n",
        "  ctx = x1 + .5 * width\n",
        "  cty = y1 + .5 * height\n",
        "\n",
        "  return width, height, ctx, cty"
      ],
      "metadata": {
        "id": "50_FCatOdh_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding `bbox` with respect to an anchor having the same center\n",
        "# should keep the first two deltas at zero.\n",
        "\n",
        "def encode(anchors, bboxes):\n",
        "  w,h,ctx,cty=get_width_upright(anchors)\n",
        "  tw,th,tctx,tcty=get_width_upright(bboxes)\n",
        "  \n",
        "  tg_dx=(tctx-ctx) / w\n",
        "  tg_dy=(tcty-cty) / h\n",
        "\n",
        "  tg_dw=torch.log(tw/w)\n",
        "  tg_dh=torch.log(th/h)\n",
        "\n",
        "  deltas=torch.stack([tg_dx,tg_dy,tg_dw,tg_dh],dim=1)\n",
        "  return deltas"
      ],
      "metadata": {
        "id": "ghU0CJ9jv2nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= torch.tensor([[0, 0, 100, 100]], dtype=torch.float32)\n",
        "b =torch.tensor([[25, 25, 75, 75]], dtype=torch.float32)\n",
        "print('With same center, first two deltas should be zero:\\n', encode(a, b))\n",
        "print(encode(a,b).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of38XV9-1vFV",
        "outputId": "d7482707-7361-4b8c-db41-5aaaf3f162f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With same center, first two deltas should be zero:\n",
            " tensor([[ 0.0000,  0.0000, -0.6833, -0.6833]])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(anchors, deltas):\n",
        "  w,h, ctx,cty = get_width_upright(anchors)\n",
        "\n",
        "  dx, dy, dw, dh = deltas[:,0],deltas[:,1],deltas[:,2],deltas[:,3]\n",
        "\n",
        "  pred_ctx = dx * w + ctx\n",
        "  pred_cty = dy * h + cty\n",
        "  pred_w = torch.exp(dw) * w\n",
        "  pred_h = torch.exp(dh) * h\n",
        "\n",
        "  bbox_x1 = pred_ctx - 0.5 * pred_w\n",
        "  bbox_y1 = pred_cty - 0.5 * pred_h\n",
        "\n",
        "  bbox_x2 = pred_ctx + 0.5 * pred_w -1.\n",
        "  bbox_y2 = pred_cty + 0.5 * pred_h -1.\n",
        "\n",
        "  bboxes = torch.stack([bbox_x1, bbox_y1, bbox_x2, bbox_y2], dim=1)\n",
        "\n",
        "  return bboxes"
      ],
      "metadata": {
        "id": "_Nzv50Oi1Wf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the round-trip: encode `bboxes` w.r.t. the anchors `anchors`\n",
        "anchor = torch.tensor([[0, 0, 100, 100],], dtype=torch.float32)\n",
        "bboxes = torch.tensor([\n",
        "    [25, 25, 75, 75],\n",
        "    [10, -205, 120, 20],\n",
        "    [-35, 37, 38, 100],\n",
        "    [-0.2, -0.2, 0.2, 0.2],\n",
        "    [-25, -50, -5, -20],], \n",
        "    dtype=torch.float32)\n",
        "print(f\"ANCHOR SHAPE: {anchor.shape} === BBOX SHAPE: {bboxes.shape}\")\n",
        "print(\n",
        "    'Round-trip looks good:',\n",
        "    torch.sum(torch.abs(\n",
        "        decode(anchor, encode(anchor, bboxes)) - bboxes\n",
        "    )) < 1e-3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv8y5LKGrqaf",
        "outputId": "afc2a621-0627-412b-b158-6d057f6b6599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANCHOR SHAPE: torch.Size([1, 4]) === BBOX SHAPE: torch.Size([5, 4])\n",
            "Round-trip looks good: tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RPN_conv(nn.Module):\n",
        "  def __init__(self,num_anchors,out=512,inp=1024):\n",
        "    #feature_map: Tensor of shape (1, W, H, C), with WxH the spatial shape of the feature map and C the number of channels (1024 in this case)\n",
        "    super(RPN_conv,self).__init__()\n",
        "    self.num_anchors=num_anchors\n",
        "    self.out_ch=out\n",
        "    self.in_ch=inp\n",
        "\n",
        "    self.conv=nn.Conv2d(self.in_ch,self.out_ch,3,1,1)\n",
        "    self.prob=nn.Conv2d(self.out_ch,num_anchors*2,1)\n",
        "    self.delt=nn.Conv2d(self.out_ch,num_anchors*4,1)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=x.permute(0,3,1,2)\n",
        "    interm=self.relu(self.conv(x))\n",
        "    out_prob=self.prob(interm).permute(0, 2, 3, 1).contiguous().view(-1, 2)\n",
        "    out_delta=self.delt(interm).permute(0, 2, 3, 1).contiguous().view(-1, 4)\n",
        "    \n",
        "    return (out_prob,out_delta)"
      ],
      "metadata": {
        "id": "_IXG3IvNEs5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map=torch.rand((1,232,232,1024))\n",
        "model=RPN_conv(15)\n",
        "prob,delt=model(feature_map)\n",
        "prob.shape,delt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qW2tIfNFJN9",
        "outputId": "2de27889-a2ec-4d11-ea3f-861a07b31289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([807360, 2]), torch.Size([807360, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_preds = (\n",
        "    feature_map.shape[1]\n",
        "    * feature_map.shape[2]\n",
        "    * len(ANCHOR_RATIOS)\n",
        "    * len(ANCHOR_SCALES)\n",
        ")"
      ],
      "metadata": {
        "id": "d947iYTrFP9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert delt.shape[0] == expected_preds , \"Numbers don't match\"\n",
        "assert prob.shape[0] == expected_preds , \"Numbers don't match\""
      ],
      "metadata": {
        "id": "4G1Q9FdJHvkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchors=torch.rand((807360,4),dtype=torch.float32)\n",
        "print(f\"ANCHOR SHAPE: {anchors.shape} === BBOX SHAPE: {delt.shape}\")\n",
        "proposals = decode(anchors, delt)\n",
        "scores=prob[:,1].reshape(-1)\n",
        "proposals.shape , scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-eUoYN1F2w1",
        "outputId": "20feecfe-5687-4a50-b519-b7d4f0a8eb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANCHOR SHAPE: torch.Size([807360, 4]) === BBOX SHAPE: torch.Size([807360, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([807360, 4]), torch.Size([807360]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_top_n(proposals, scores, topn):\n",
        "  num_proposals=proposals.shape[0]\n",
        "  if num_proposals <= topn:\n",
        "    return proposals, scores\n",
        "  else:\n",
        "    indices=torch.argsort(scores,descending=True)\n",
        "    top_indices = indices[:topn]\n",
        "    sorted_top_proposals=proposals[top_indices]\n",
        "    sorted_top_scores=scores[top_indices]\n",
        "  return sorted_top_proposals, sorted_top_scores\n",
        "proposals,scores=keep_top_n(proposals,scores,3000)\n",
        "print(f'PROPOSALS SHAPE: {proposals.shape} \\n SCORES SHAPE: {scores.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkO4hjhAJScG",
        "outputId": "b4ea1845-5f8b-490c-abcb-b9edca36ff50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROPOSALS SHAPE: torch.Size([3000, 4]) \n",
            " SCORES SHAPE: torch.Size([3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_boxes(bboxes,im_shape): #We usually apply this on proposals after decode\n",
        "  x1,y1,x2,y2=bboxes[:,0],bboxes[:,1],bboxes[:,2],bboxes[:,3]\n",
        "  width,height=im_shape.shape[1],im_shape.shape[2]\n",
        "\n",
        "  x1=torch.maximum(torch.minimum(x1,width-1),0.0)\n",
        "  x2=torch.maximum(torch.minimum(x2,width-1),0.0)\n",
        "  y1=torch.maximum(torch.minimum(y1,height-1),0.0)\n",
        "  y2=torch.maximum(torch.minimum(y2,height-1),0.0)\n",
        "\n",
        "  bboxes=torch.stack([x1,y1,x2,y2],dim=1)\n",
        "  \n",
        "  return bboxes"
      ],
      "metadata": {
        "id": "q1bMp6UtLeb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def filter_proposals(bbox_preds,class_preds): clip_boxes, apply area and prob filters + nms"
      ],
      "metadata": {
        "id": "xjx9ieDaxLzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_boxes(proposals,im_shape):\n",
        "  x1,y1,x2,y2=proposals[:,0],proposals[:,1],proposals[:,2],proposals[:,3]\n",
        "  x1 = x1 / im_shape[1]\n",
        "  y1 = y1 / im_shape[0]\n",
        "  x2 = x2 / im_shape[1]\n",
        "  y2 = y2 / im_shape[0]\n",
        "\n",
        "  return torch.stack([x1,y1,x2,y2],dim=1)\n",
        "\n",
        "def roi_crop(proposals,ft_map,im_shape,pooled_width,pooled_height):\n",
        "  bboxes=normalize_boxes(proposals,im_shape)\n",
        "  bboxes_shape=bboxes.shape\n",
        "  batch_ids=torch.zeros((bboxes_shape[0],),dtype=torch.int32)\n",
        "\n",
        "  crops=torch.resized_crop(ft_map,bboxes,batch_ids,[pooled_width * 2, pooled_height * 2])\n",
        "  pool=nn.MaxPool2d(2,2)\n",
        "  out=pool(crops)\n",
        "  return out"
      ],
      "metadata": {
        "id": "p5ihT72lSXJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def run_rcnn(pooled, num_classes):\n",
        "  #pooled: Pooled feature map, with shape `(num_proposals,pool_size, pool_size, feature_map_channels)`.\n",
        "  #Returns: Tuple of Tensors (`(W * H * proposals, 4)`, `(pool_size ^ 2 * proposals, num_classes)`)\n",
        "\n",
        "  #1.Run pooled through the tail of ResNet + global average pooling\n",
        "  #2. Run through fully-connected + softmax"
      ],
      "metadata": {
        "id": "l613G4zjkymw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS3OrL2o8Uuz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}